{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "import os\n",
    "def eliminar_contenido_path(path):\n",
    "    for archivo in os.listdir(path):\n",
    "        os.remove(os.path.join(path, archivo))\n",
    "    \n",
    "eliminar_contenido_path('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conexión a la base de datos SQLite\n",
    "conn = sqlite3.connect('./data/metadatos.db')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Creación de la tabla para almacenar metadatos\n",
    "cursor.execute('''\n",
    "CREATE TABLE IF NOT EXISTS documentos (\n",
    "    id TEXT PRIMARY KEY,\n",
    "    file_path TEXT,\n",
    "    file TEXT,\n",
    "    pagina INTEGER\n",
    ")\n",
    "''')\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Configuración de ChromaDB\n",
    "persist_directory = './data/chroma_db'\n",
    "embedding_model = SentenceTransformerEmbeddings(model_name=\"LaBSE\")\n",
    "vector_store = Chroma(embedding_function=embedding_model, persist_directory=persist_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1w/2mpv0jw11qj_v4tpnrdqv7t40000gn/T/ipykernel_1363/479594108.py:2: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = SentenceTransformerEmbeddings(model_name=\"LaBSE\")\n",
      "/Users/mhurben/anaconda3/envs/proy/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Inicializar el modelo de embeddings (usando LaBSE en este ejemplo)\n",
    "embedding_model = SentenceTransformerEmbeddings(model_name=\"LaBSE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No se encontró índice FAISS previo. Se creará uno nuevo.\n"
     ]
    }
   ],
   "source": [
    "faiss_index_dir = 'data/faiss_index'\n",
    "\n",
    "# Si el directorio existe y tiene contenido, cargamos el índice FAISS; sino, lo inicializamos en None.\n",
    "if os.path.exists(faiss_index_dir) and os.listdir(faiss_index_dir):\n",
    "    faiss_vector_store = FAISS.load_local(faiss_index_dir, embedding_model)\n",
    "    print(\"Índice FAISS cargado desde disco.\")\n",
    "else:\n",
    "    faiss_vector_store = None\n",
    "    print(\"No se encontró índice FAISS previo. Se creará uno nuevo.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Función para procesar un PDF y agregar sus fragmentos a FAISS y SQLite\n",
    "# ----------------------------\n",
    "def procesar_pdf(file_path):\n",
    "    global faiss_vector_store\n",
    "\n",
    "    # Cargar el documento PDF\n",
    "    loader = PyPDFLoader(file_path)\n",
    "    documentos = loader.load()\n",
    "\n",
    "    # Dividir el contenido en fragmentos de 768 tokens (con 50 tokens de solapamiento)\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=768, overlap_size=50)\n",
    "    documentos_divididos = text_splitter.split_documents(documentos)\n",
    "\n",
    "    for i, doc in enumerate(documentos_divididos):\n",
    "        # Extraer la etiqueta de página o asignar un valor por defecto\n",
    "        page = doc.metadata.get('page_label', f\"pagina_{i}\")\n",
    "\n",
    "        # Obtener el nombre base del archivo\n",
    "        file_name = file_path.split(\"/\")[-1]\n",
    "        nombre_sin_ext = file_name.split(\".\")[0]\n",
    "\n",
    "        # Crear un ID único para cada fragmento\n",
    "        doc_id = f'{nombre_sin_ext}-{page}-{i}'\n",
    "\n",
    "        # Si el índice FAISS aún no se ha creado, lo inicializamos con el primer fragmento\n",
    "        if faiss_vector_store is None:\n",
    "            faiss_vector_store = FAISS.from_documents(\n",
    "                [doc],\n",
    "                embedding_model,\n",
    "                ids=[doc_id]\n",
    "            )\n",
    "        else:\n",
    "            # Agregar nuevos fragmentos al índice existente\n",
    "            faiss_vector_store.add_texts(\n",
    "                texts=[doc.page_content],\n",
    "                ids=[doc_id]\n",
    "            )\n",
    "\n",
    "        # Almacenar metadatos en SQLite\n",
    "        cursor.execute('''\n",
    "        INSERT INTO documentos (id, file_path, file, pagina)\n",
    "        VALUES (?, ?, ?, ?)\n",
    "        ''', (doc_id, file_path, file_name, page))\n",
    "        conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de rutas de archivos PDF a procesar\n",
    "rutas_pdfs = ['../01_data/2022202200133100001545.pdf', '../01_data/U0924996.pdf']\n",
    "\n",
    "for ruta_pdf in rutas_pdfs:\n",
    "    procesar_pdf(ruta_pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Índice FAISS guardado en disco.\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------\n",
    "# Persistir el índice FAISS en disco para su uso en futuras ejecuciones\n",
    "# --------------------------------------------------------\n",
    "if faiss_vector_store is not None:\n",
    "    faiss_vector_store.save_local(faiss_index_dir)\n",
    "    print(\"Índice FAISS guardado en disco.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtener_id_por_metadatos(file_path):\n",
    "    cursor.execute(f\"\"\"\n",
    "    SELECT * FROM documentos WHERE file_path = '{file_path}'\n",
    "    \"\"\")\n",
    "    #Todos los resultados\n",
    "    resultados = cursor.fetchall()\n",
    "    return resultados if resultados else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_id = obtener_id_por_metadatos('../01_data/2022202200133100001545.pdf')\n",
    "len(doc_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Busqueda de documentos\n",
    "\n",
    "def buscar_documentos(query, k=5):\n",
    "    vector_store = FAISS.load_local(faiss_index_dir, embedding_model, allow_dangerous_deserialization = True)\n",
    "\n",
    "    # Obtener el embedding de la consulta\n",
    "    query_embedding = embedding_model.embed_query(query)\n",
    "\n",
    "    # Realizar búsqueda en el índice FAISS\n",
    "    resultados = vector_store.similarity_search_with_score_by_vector(query_embedding, k=k) # DISTANCE L2\n",
    "\n",
    "    return resultados\n",
    "\n",
    "# Consulta de ejemplo\n",
    "query = \"¿Cuántos períodos se habilitan cada curso académico para solicitar concurrir a los actos extraordinarios de evaluación?\"\n",
    "resultados = buscar_documentos(query, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'también en Consejo de Gobierno de 3 de febrero de 2022, señala que cada curso académico \\nse habilitarán tres períodos para solicitar concurrir a los actos extraordinarios de evaluación, \\nen los que el alumnado podrá solicitar indistintamente concurrir a actos extraordinarios de \\nevaluación de asignaturas del primer semestre, segundo semestre o anuales. En dicha norma \\nse señala que el calendario académico de cada curso establecerá las fechas de realización de'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados[0][0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documento 2022202200133100001545.pdf eliminado del índice FAISS.\n"
     ]
    }
   ],
   "source": [
    "def eliminar_documento(file_name):\n",
    "    cursor.execute(f\"\"\"\n",
    "    SELECT id FROM documentos WHERE file = '{file_name}'\n",
    "    \"\"\")\n",
    "    conn.commit()\n",
    "\n",
    "    doc_ids = cursor.fetchall()\n",
    "    doc_ids = [id[0] for id in doc_ids]\n",
    "\n",
    "    # MODIFICAR LA BD PARA PONER LA COLUMNA EN_USO = FALSE\n",
    "\n",
    "    if doc_ids:\n",
    "        faiss_vector_store.delete(doc_ids)\n",
    "    \n",
    "    print(f\"Documento {file_name} eliminado del índice FAISS.\")\n",
    "\n",
    "eliminar_documento('2022202200133100001545.pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
