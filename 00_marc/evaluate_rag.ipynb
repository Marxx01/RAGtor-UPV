{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ce9702be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from get_response import PoliGPT\n",
    "import rag_metrics as rm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "34aff15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "preguntas = [\n",
    "    \"¿Es necesario el conocimiento de Valenciano para acceder a una plaza en la Universidad?\",\n",
    "    \"¿Cuáles son los requisitos para estudiar en la Universidad?\",\n",
    "    \"¿Qué carreras se ofrecen en la Universidad?\",\n",
    "    \"¿Hay becas disponibles para estudiantes?\",\n",
    "    \"¿Qué tipo de apoyo académico se ofrece a los estudiantes?\",\n",
    "    \"¿Cómo se puede acceder a la información sobre las becas?\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a48f11bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS inicializado - Vectores: 79044 | Dimensión: 768\n"
     ]
    }
   ],
   "source": [
    "poligpt = PoliGPT(faiss_index_dir='../01_data/project_faiss')\n",
    "respuestas = []\n",
    "for pregunta in preguntas:  \n",
    "    respuesta = poligpt.query_poligpt(pregunta, k_context=2)\n",
    "    if respuesta['response'] != 'No dispongo de información suficiente en el contexto proporcionado.':\n",
    "        respuestas.append(respuesta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "861183c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_contexts(respuestas):\n",
    "    \"\"\"\n",
    "    Formatea los contextos para valorar las métricas de RAG.\n",
    "    \"\"\"\n",
    "    c = []\n",
    "    for respuesta in respuestas:\n",
    "        contexts = respuesta['contexts']\n",
    "        c_aux = []\n",
    "        for context in contexts:\n",
    "            c_aux.append(context['content'])\n",
    "        c.append(c_aux)\n",
    "    return c\n",
    "\n",
    "contextos = format_contexts(respuestas)\n",
    "respuestas_final = [dic['response'] for dic in respuestas]\n",
    "preguntas_final = [dic['query'] for dic in respuestas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9d70a2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_dataset(preguntas, respuestas, contextos):\n",
    "    \"\"\"Aggregate the three metrics over an iterable of RAG records.\"\"\"\n",
    "    g_scores, f1s, qc_sims = [], [], []\n",
    "    for answer, contexts, question in zip(respuestas, contextos,preguntas):\n",
    "        g_scores.append(rm.grounding_score(answer, contexts))\n",
    "        f1s.append(rm.context_overlap_f1(answer, contexts))\n",
    "        qc_sims.append(rm.question_context_similarity(question, contexts))\n",
    "    n = max(len(g_scores), 1)\n",
    "    return {\n",
    "        \"Grounding\": sum(g_scores) / n,\n",
    "        \"ContextOverlapF1\": sum(f1s) / n,\n",
    "        \"QuestionContextSim\": sum(qc_sims) / n,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8b09d836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Grounding': 0.5104868526846762,\n",
       " 'ContextOverlapF1': 0.2762784210576794,\n",
       " 'QuestionContextSim': 0.04147109444696931}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_dataset(preguntas_final, respuestas_final, contextos)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
