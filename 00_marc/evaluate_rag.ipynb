{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce9702be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from get_response import PoliGPT\n",
    "from typing import Any, Dict, List, Sequence, Mapping # Mapping es más general que Dict\n",
    "from datasets import Dataset\n",
    "\n",
    "# --- NECESITAS DEFINIR ESTAS RESPUESTAS DE REFERENCIA ---\n",
    "# Estas son las respuestas \"correctas\" o \"ideales\" para cada pregunta.\n",
    "# Tendrás que escribirlas tú mismo basándote en el conocimiento esperado.\n",
    "# Ejemplo (DEBES RELLENARLAS CON LAS RESPUESTAS CORRECTAS REALES):\n",
    "ground_truths: Dict[str, str] = {\n",
    "    \"¿Es necesario el conocimiento de Valenciano para acceder a una plaza en la Universidad?\": \"\",\n",
    "    \"¿Cuáles son los requisitos para estudiar en la Universidad?\": \"\",\n",
    "    \"¿Hay becas disponibles para estudiantes?\": \"\",\n",
    "    \"¿Qué tipo de apoyo académico se ofrece a los estudiantes?\": \"\",\n",
    "    \"¿Cómo se puede acceder a la información sobre las becas?\": \"\",\n",
    "}\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "\n",
    "def build_eval_dataset(\n",
    "    client: \"PoliGPT\",\n",
    "    questions: Sequence[str],\n",
    "    ground_truths: Mapping[str, str], # Añadido: Acepta las respuestas de referencia\n",
    "    k_context: int = 3\n",
    ") -> Dataset:\n",
    "    \"\"\"Construye un *Dataset* de `datasets` compatible con *Ragas*.\n",
    "\n",
    "    Args:\n",
    "        client: Instancia de :class:`PoliGPT`.\n",
    "        questions: Lista de preguntas a evaluar.\n",
    "        ground_truths: Diccionario mapeando preguntas a sus respuestas de referencia.\n",
    "        k_context: Nº de fragmentos de contexto que se solicitarán a PoliGPT.\n",
    "\n",
    "    Returns:\n",
    "        Dataset con columnas 'question', 'contexts', 'answer' y 'reference'.\n",
    "    \"\"\"\n",
    "    rows: Dict[str, List[Any]] = {\n",
    "        \"question\": [],\n",
    "        \"contexts\": [],\n",
    "        \"answer\": [],\n",
    "        \"reference\": [] # Añadida la columna para las respuestas de referencia\n",
    "    }\n",
    "\n",
    "    for q in questions:\n",
    "        # Asegúrate de que hay una respuesta de referencia para esta pregunta\n",
    "        if q not in ground_truths:\n",
    "            print(f\"Advertencia: No se encontró respuesta de referencia (ground truth) para la pregunta: '{q}'. Saltando...\")\n",
    "            continue\n",
    "\n",
    "        res = client.query_poligpt(q, k_context=k_context)\n",
    "\n",
    "        # Salta en caso de error en la consulta a PoliGPT\n",
    "        if \"error\" in res:\n",
    "            print(f\"Pregunta ignorada por falta de contexto o error en PoliGPT: '{q}'\")\n",
    "            continue\n",
    "\n",
    "        rows[\"question\"].append(q)\n",
    "        rows[\"answer\"].append(res[\"response\"])\n",
    "        rows[\"contexts\"].append([c[\"content\"] for c in res[\"contexts\"]])\n",
    "        rows[\"reference\"].append(ground_truths[q]) # Añade la respuesta de referencia correspondiente\n",
    "\n",
    "    # Verifica que todas las listas tengan la misma longitud antes de crear el Dataset\n",
    "    list_lengths = {key: len(value) for key, value in rows.items()}\n",
    "    if len(set(list_lengths.values())) > 1:\n",
    "        print(\"Error: Las listas de columnas tienen diferentes longitudes:\", list_lengths)\n",
    "        # Decide cómo manejar esto: ¿lanzar un error, devolver un dataset vacío, etc.?\n",
    "        # Por ahora, simplemente imprimimos y devolvemos un dataset vacío o parcial\n",
    "        # Podrías intentar filtrar las filas incompletas si es apropiado\n",
    "        non_empty_rows = {k: v for k, v in rows.items() if v}\n",
    "        if not non_empty_rows or len(set(len(lst) for lst in non_empty_rows.values())) > 1 :\n",
    "             return Dataset.from_dict({\"question\":[], \"contexts\":[], \"answer\":[], \"reference\":[]}) # O lanzar excepción\n",
    "        # Intentar crear con las columnas que sí tienen datos (si todas tienen la misma longitud > 0)\n",
    "        min_len = min(len(v) for v in non_empty_rows.values())\n",
    "        rows_truncated = {k: v[:min_len] for k, v in non_empty_rows.items()}\n",
    "        print(\"Advertencia: Creando dataset con datos truncados debido a longitudes desiguales.\")\n",
    "        return Dataset.from_dict(rows_truncated)\n",
    "\n",
    "\n",
    "    # Si no hay datos válidos después de filtrar, devuelve un dataset vacío\n",
    "    if not rows[\"question\"]:\n",
    "         print(\"Advertencia: No se generaron filas válidas para el dataset de evaluación.\")\n",
    "         return Dataset.from_dict({\"question\":[], \"contexts\":[], \"answer\":[], \"reference\":[]})\n",
    "\n",
    "\n",
    "    return Dataset.from_dict(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34aff15d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS inicializado - Vectores: 79044 | Dimensión: 768\n",
      "Dataset construido:\n",
      "Dataset({\n",
      "    features: ['question', 'contexts', 'answer', 'reference'],\n",
      "    num_rows: 1\n",
      "})\n",
      "Pregunta: ¿Cuáles son los requisitos para estudiar en la Universidad?\n",
      "Respuesta: Los requisitos para estudiar en la Universidad son:\n",
      "\n",
      "a) Estar matriculado y tener consideración de alumno de la Universitat Politècnica de València.\n",
      "b) Para prácticas externas curriculares de grado, máster y títulos propios, estar matriculado en los créditos de prácticas y cumplir requisitos específicos del plan de estudios o estructura responsable del título.\n",
      "c) Para prácticas externas curriculares de grado, con carácter general (sin detalles adicionales proporcionados).\n",
      "\n",
      "No se cita normativa relevante específica más allá de los puntos a), b) y c) mencionados. Si se requiere información adicional sobre algún punto específico, no hay suficiente detalle en el contexto proporcionado.\n",
      "Contextos: ['estudiants han de complir els requisits següents:\\na) Estar matriculat i tenir consideració d’alumne\\nde la Universitat Politècnica de València.\\nb) En el cas de pràctiques externes curriculars,\\nper a les titulacions de grau, màster i títols pro-\\npis, estar matriculat en els crèdits de pràcti-\\nques i complir els requisits especiﬁcats en el\\npla d’estudis i/o per l’estructura responsable\\ndel títol.\\nc) En el cas de pràctiques externes curriculars,\\nper a les titulacions de grau i amb caràcter', 'L’article 2 dels Estatuts de la Universitat  Politècnica  \\nde València, en els epígrafs a i d, defineix els fins \\nsegüents de la Universitat:  \\n• La finalitat essencial és la formació integral dels\\n \\nestudiants  a través de la creació, desenvolupament,  \\ntransmissió  i crítica de la ciència, de la tècnica, de \\nl’art i de la cultura, des del respecte als principis \\nètics, amb una decidida orientació  a la consecució  \\nd’una ocupació d’acord amb el seu nivell d’estudis.', 'bases  con los requisitos  y el baremo  para  asignarlas,  que incluirá  la valoración  de los años  \\nde servicio  en la UPV,  los resultados  de la actividad  investigadora  y/o docente,  y la \\nvaloración  del programa  de actividades  del personal  solicitante,  teniendo  en cuenta  la \\nadecuación  del mismo  a las necesidades  docentes  e investigadoras,   presentes   y  futuras,  \\ndel Departamento,  así como  la calidad  e idoneidad  para  ser desarrollado  en el centro  receptor.']\n",
      "Referencia: \n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# --- Script Principal ---\n",
    "\n",
    "preguntas = [\n",
    "    #\"¿Es necesario el conocimiento de Valenciano para acceder a una plaza en la Universidad?\",\n",
    "    \"¿Cuáles son los requisitos para estudiar en la Universidad?\",\n",
    "    #\"¿Qué carreras se ofrecen en la Universidad?\",\n",
    "    #\"¿Hay becas disponibles para estudiantes?\",\n",
    "    #\"¿Qué tipo de apoyo académico se ofrece a los estudiantes?\",\n",
    "    #\"¿Cómo se puede acceder a la información sobre las becas?\",\n",
    "]\n",
    "\n",
    "# Cargar el cliente PoliGPT\n",
    "# Asegúrate de que la ruta al índice FAISS sea correcta\n",
    "try:\n",
    "    poligpt = PoliGPT(faiss_index_dir='../01_data/project_faiss')\n",
    "except Exception as e:\n",
    "    print(f\"Error al cargar PoliGPT: {e}\")\n",
    "    # Salir o manejar el error adecuadamente\n",
    "    exit()\n",
    "\n",
    "# Construir el dataset de evaluación, pasando las respuestas de referencia\n",
    "eval_ds = build_eval_dataset(poligpt, preguntas, ground_truths, k_context=3)\n",
    "\n",
    "# Verificar si el dataset se construyó correctamente\n",
    "print(\"Dataset construido:\")\n",
    "print(eval_ds)\n",
    "\n",
    "for i in range(len(eval_ds)):\n",
    "    print(f\"Pregunta: {eval_ds['question'][i]}\")\n",
    "    print(f\"Respuesta: {eval_ds['answer'][i]}\")\n",
    "    print(f\"Contextos: {eval_ds['contexts'][i]}\")\n",
    "    print(f\"Referencia: {eval_ds['reference'][i]}\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     15\u001b[39m predicciones = {\n\u001b[32m     16\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m¿Qué es RAG?\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mLa respuesta generada por tu sistema RAG...\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     17\u001b[39m }\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Realizar evaluación\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m resultados = \u001b[43meval_chain\u001b[49m\u001b[43m.\u001b[49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mejemplos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredicciones\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/proy/lib/python3.11/site-packages/langchain/evaluation/qa/eval_chain.py:138\u001b[39m, in \u001b[36mQAEvalChain.evaluate\u001b[39m\u001b[34m(self, examples, predictions, question_key, answer_key, prediction_key, callbacks)\u001b[39m\n\u001b[32m    127\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mevaluate\u001b[39m(\n\u001b[32m    128\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    129\u001b[39m     examples: Sequence[\u001b[38;5;28mdict\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m    135\u001b[39m     callbacks: Callbacks = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    136\u001b[39m ) -> List[\u001b[38;5;28mdict\u001b[39m]:\n\u001b[32m    137\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Evaluate question answering examples and predictions.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m138\u001b[39m     inputs = \u001b[43m[\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    140\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mquery\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample\u001b[49m\u001b[43m[\u001b[49m\u001b[43mquestion_key\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43manswer\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample\u001b[49m\u001b[43m[\u001b[49m\u001b[43manswer_key\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    142\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresult\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mprediction_key\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    143\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m    144\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mexamples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    145\u001b[39m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.apply(inputs, callbacks=callbacks)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/proy/lib/python3.11/site-packages/langchain/evaluation/qa/eval_chain.py:142\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    127\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mevaluate\u001b[39m(\n\u001b[32m    128\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    129\u001b[39m     examples: Sequence[\u001b[38;5;28mdict\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m    135\u001b[39m     callbacks: Callbacks = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    136\u001b[39m ) -> List[\u001b[38;5;28mdict\u001b[39m]:\n\u001b[32m    137\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Evaluate question answering examples and predictions.\"\"\"\u001b[39;00m\n\u001b[32m    138\u001b[39m     inputs = [\n\u001b[32m    139\u001b[39m         {\n\u001b[32m    140\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mquery\u001b[39m\u001b[33m\"\u001b[39m: example[question_key],\n\u001b[32m    141\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33manswer\u001b[39m\u001b[33m\"\u001b[39m: example[answer_key],\n\u001b[32m--> \u001b[39m\u001b[32m142\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mresult\u001b[39m\u001b[33m\"\u001b[39m: \u001b[43mpredictions\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m[prediction_key],\n\u001b[32m    143\u001b[39m         }\n\u001b[32m    144\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m i, example \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(examples)\n\u001b[32m    145\u001b[39m     ]\n\u001b[32m    147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.apply(inputs, callbacks=callbacks)\n",
      "\u001b[31mKeyError\u001b[39m: 0"
     ]
    }
   ],
   "source": [
    "# Ejemplo conceptual de uso de nuclia-eval\n",
    "from nuclia_eval import REMiEvaluator\n",
    "import ollama\n",
    "# Configurar el evaluador con un modelo de Ollama\n",
    "# Asegúrate de que el modelo esté disponible en tu entorno\n",
    "# Puedes usar un modelo de Ollama o un modelo local\n",
    "# evaluador = REMiEvaluator(model=\"llama2\", model_type=\"ollama\")\n",
    "\n",
    "# Configurar el evaluador con un modelo local\n",
    "\n",
    "evaluador = REMiEvaluator(model=\"deepseek-r1:14b\", model_type=\"ollama\", device=\"mps\")\n",
    "\n",
    "preguntas = eval_ds[\"question\"]\n",
    "respuestas = eval_ds[\"answer\"]\n",
    "contextos = eval_ds[\"contexts\"]\n",
    "\n",
    "# Evaluar resultados RAG\n",
    "resultados = evaluador.evaluate(\n",
    "    preguntas=preguntas,\n",
    "    respuestas_generadas=respuestas,\n",
    "    contextos_recuperados=contextos\n",
    ")\n",
    "\n",
    "# Analizar resultados\n",
    "print(resultados.metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
