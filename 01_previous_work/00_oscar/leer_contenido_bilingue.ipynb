{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import PyPDF2\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "pdf_folder = \"/content/drive/My Drive/clase 3 carrera/PROY3/Archivos/\"\n",
    "import pdfplumber\n",
    "from pdfplumber.table import TableFinder\n",
    "from langchain.schema import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cpu\n",
      "Collecting torch==2.0.1\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torch-2.0.1%2Bcpu-cp311-cp311-win_amd64.whl (174.0 MB)\n",
      "     ---------------------------------------- 0.0/174.0 MB ? eta -:--:--\n",
      "     --------------------------------------- 2.1/174.0 MB 11.8 MB/s eta 0:00:15\n",
      "      -------------------------------------- 4.5/174.0 MB 11.7 MB/s eta 0:00:15\n",
      "     - ------------------------------------- 7.1/174.0 MB 11.8 MB/s eta 0:00:15\n",
      "     -- ------------------------------------ 9.7/174.0 MB 11.6 MB/s eta 0:00:15\n",
      "     -- ----------------------------------- 12.3/174.0 MB 11.7 MB/s eta 0:00:14\n",
      "     --- ---------------------------------- 14.7/174.0 MB 11.7 MB/s eta 0:00:14\n",
      "     --- ---------------------------------- 17.3/174.0 MB 11.7 MB/s eta 0:00:14\n",
      "     ---- --------------------------------- 19.9/174.0 MB 11.6 MB/s eta 0:00:14\n",
      "     ---- --------------------------------- 22.3/174.0 MB 11.6 MB/s eta 0:00:14\n",
      "     ----- -------------------------------- 24.9/174.0 MB 11.7 MB/s eta 0:00:13\n",
      "     ----- -------------------------------- 27.3/174.0 MB 11.7 MB/s eta 0:00:13\n",
      "     ------ ------------------------------- 29.6/174.0 MB 11.7 MB/s eta 0:00:13\n",
      "     ------ ------------------------------- 32.0/174.0 MB 11.7 MB/s eta 0:00:13\n",
      "     ------- ------------------------------ 34.6/174.0 MB 11.7 MB/s eta 0:00:12\n",
      "     -------- ----------------------------- 37.0/174.0 MB 11.7 MB/s eta 0:00:12\n",
      "     -------- ----------------------------- 39.6/174.0 MB 11.7 MB/s eta 0:00:12\n",
      "     --------- ---------------------------- 41.9/174.0 MB 11.7 MB/s eta 0:00:12\n",
      "     --------- ---------------------------- 44.3/174.0 MB 11.7 MB/s eta 0:00:12\n",
      "     ---------- --------------------------- 46.9/174.0 MB 11.7 MB/s eta 0:00:11\n",
      "     ---------- --------------------------- 49.5/174.0 MB 11.7 MB/s eta 0:00:11\n",
      "     ----------- -------------------------- 51.9/174.0 MB 11.7 MB/s eta 0:00:11\n",
      "     ----------- -------------------------- 54.3/174.0 MB 11.6 MB/s eta 0:00:11\n",
      "     ------------ ------------------------- 56.6/174.0 MB 11.7 MB/s eta 0:00:11\n",
      "     ------------ ------------------------- 59.0/174.0 MB 11.7 MB/s eta 0:00:10\n",
      "     ------------- ------------------------ 61.6/174.0 MB 11.7 MB/s eta 0:00:10\n",
      "     ------------- ------------------------ 64.0/174.0 MB 11.7 MB/s eta 0:00:10\n",
      "     -------------- ----------------------- 66.3/174.0 MB 11.6 MB/s eta 0:00:10\n",
      "     -------------- ----------------------- 68.7/174.0 MB 11.6 MB/s eta 0:00:10\n",
      "     --------------- ---------------------- 71.0/174.0 MB 11.6 MB/s eta 0:00:09\n",
      "     ---------------- --------------------- 73.4/174.0 MB 11.7 MB/s eta 0:00:09\n",
      "     ---------------- --------------------- 76.0/174.0 MB 11.7 MB/s eta 0:00:09\n",
      "     ----------------- -------------------- 78.4/174.0 MB 11.7 MB/s eta 0:00:09\n",
      "     ----------------- -------------------- 80.7/174.0 MB 11.6 MB/s eta 0:00:09\n",
      "     ------------------ ------------------- 83.4/174.0 MB 11.6 MB/s eta 0:00:08\n",
      "     ------------------ ------------------- 86.0/174.0 MB 11.6 MB/s eta 0:00:08\n",
      "     ------------------- ------------------ 88.3/174.0 MB 11.6 MB/s eta 0:00:08\n",
      "     ------------------- ------------------ 90.7/174.0 MB 11.6 MB/s eta 0:00:08\n",
      "     -------------------- ----------------- 93.1/174.0 MB 11.6 MB/s eta 0:00:07\n",
      "     -------------------- ----------------- 95.7/174.0 MB 11.7 MB/s eta 0:00:07\n",
      "     --------------------- ---------------- 98.0/174.0 MB 11.7 MB/s eta 0:00:07\n",
      "     --------------------- --------------- 100.7/174.0 MB 11.6 MB/s eta 0:00:07\n",
      "     --------------------- --------------- 103.0/174.0 MB 11.6 MB/s eta 0:00:07\n",
      "     ---------------------- -------------- 105.6/174.0 MB 11.6 MB/s eta 0:00:06\n",
      "     ----------------------- ------------- 108.3/174.0 MB 11.7 MB/s eta 0:00:06\n",
      "     ----------------------- ------------- 110.6/174.0 MB 11.7 MB/s eta 0:00:06\n",
      "     ------------------------ ------------ 113.2/174.0 MB 11.7 MB/s eta 0:00:06\n",
      "     ------------------------ ------------ 115.6/174.0 MB 11.7 MB/s eta 0:00:06\n",
      "     ------------------------- ----------- 118.0/174.0 MB 11.7 MB/s eta 0:00:05\n",
      "     ------------------------- ----------- 120.3/174.0 MB 11.7 MB/s eta 0:00:05\n",
      "     -------------------------- ---------- 122.9/174.0 MB 11.6 MB/s eta 0:00:05\n",
      "     -------------------------- ---------- 125.3/174.0 MB 11.7 MB/s eta 0:00:05\n",
      "     --------------------------- --------- 127.9/174.0 MB 11.7 MB/s eta 0:00:04\n",
      "     --------------------------- --------- 130.3/174.0 MB 11.7 MB/s eta 0:00:04\n",
      "     ---------------------------- -------- 132.9/174.0 MB 11.7 MB/s eta 0:00:04\n",
      "     ---------------------------- -------- 135.3/174.0 MB 11.7 MB/s eta 0:00:04\n",
      "     ----------------------------- ------- 137.6/174.0 MB 11.6 MB/s eta 0:00:04\n",
      "     ----------------------------- ------- 140.2/174.0 MB 11.7 MB/s eta 0:00:03\n",
      "     ------------------------------ ------ 142.9/174.0 MB 11.7 MB/s eta 0:00:03\n",
      "     ------------------------------ ------ 145.2/174.0 MB 11.7 MB/s eta 0:00:03\n",
      "     ------------------------------- ----- 147.6/174.0 MB 11.7 MB/s eta 0:00:03\n",
      "     ------------------------------- ----- 150.5/174.0 MB 11.6 MB/s eta 0:00:03\n",
      "     -------------------------------- ---- 152.8/174.0 MB 11.6 MB/s eta 0:00:02\n",
      "     --------------------------------- --- 155.5/174.0 MB 11.6 MB/s eta 0:00:02\n",
      "     --------------------------------- --- 157.8/174.0 MB 11.6 MB/s eta 0:00:02\n",
      "     ---------------------------------- -- 160.2/174.0 MB 11.6 MB/s eta 0:00:02\n",
      "     ---------------------------------- -- 162.8/174.0 MB 11.6 MB/s eta 0:00:01\n",
      "     ----------------------------------- - 165.4/174.0 MB 11.6 MB/s eta 0:00:01\n",
      "     ----------------------------------- - 168.0/174.0 MB 11.6 MB/s eta 0:00:01\n",
      "     ------------------------------------  170.4/174.0 MB 11.6 MB/s eta 0:00:01\n",
      "     ------------------------------------  172.8/174.0 MB 11.6 MB/s eta 0:00:01\n",
      "     ------------------------------------  173.8/174.0 MB 11.6 MB/s eta 0:00:01\n",
      "     ------------------------------------  173.8/174.0 MB 11.6 MB/s eta 0:00:01\n",
      "     ------------------------------------- 174.0/174.0 MB 11.3 MB/s eta 0:00:00\n",
      "Collecting torchvision==0.15.2\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torchvision-0.15.2%2Bcpu-cp311-cp311-win_amd64.whl (1.2 MB)\n",
      "     ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "     ---------------------------------------- 1.2/1.2 MB 7.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: filelock in c:\\users\\ojeem\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch==2.0.1) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\ojeem\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch==2.0.1) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\ojeem\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch==2.0.1) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\ojeem\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch==2.0.1) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ojeem\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch==2.0.1) (3.1.6)\n",
      "Requirement already satisfied: numpy in c:\\users\\ojeem\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torchvision==0.15.2) (2.2.4)\n",
      "Requirement already satisfied: requests in c:\\users\\ojeem\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torchvision==0.15.2) (2.32.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\ojeem\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torchvision==0.15.2) (11.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ojeem\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jinja2->torch==2.0.1) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ojeem\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->torchvision==0.15.2) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ojeem\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->torchvision==0.15.2) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ojeem\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->torchvision==0.15.2) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ojeem\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->torchvision==0.15.2) (2025.1.31)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\ojeem\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sympy->torch==2.0.1) (1.3.0)\n",
      "Installing collected packages: torch, torchvision\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.7.0\n",
      "    Uninstalling torch-2.7.0:\n",
      "      Successfully uninstalled torch-2.7.0\n",
      "Successfully installed torch-2.0.1+cpu torchvision-0.15.2+cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: C:\\Users\\ojeem\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==2.0.1 torchvision==0.15.2 --index-url https://download.pytorch.org/whl/cpu "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Torch: 2.0.1+cpu\n",
      "✅ TorchVision: 0.15.2+cpu\n",
      "🔥 ¡NMS funciona correctamente!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "print(f\"✅ Torch: {torch.__version__}\")\n",
    "print(f\"✅ TorchVision: {torchvision.__version__}\")\n",
    "\n",
    "from torchvision.ops import nms\n",
    "print(\"🔥 ¡NMS funciona correctamente!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def load_pdf_by_language(file_path: str) -> list[Document]:\n",
    "    \"\"\"\n",
    "    Carga un PDF separando contenido en valenciano y castellano,\n",
    "    agrupando todo el contenido por idioma en documentos únicos\n",
    "    \"\"\"\n",
    "    valencia_content = []\n",
    "    castellano_content = []\n",
    "\n",
    "    with pdfplumber.open(file_path) as pdf:\n",
    "        for page_num, page in enumerate(pdf.pages):\n",
    "            # Configuración para detección de tablas\n",
    "            table_settings = {\n",
    "                \"vertical_strategy\": \"lines\",\n",
    "                \"horizontal_strategy\": \"lines\",\n",
    "                \"snap_tolerance\": 4,\n",
    "                \"join_tolerance\": 10\n",
    "            }\n",
    "\n",
    "            # Procesar tablas primero\n",
    "            tf = TableFinder(page, table_settings)\n",
    "            table_bboxes = []\n",
    "            width = page.width\n",
    "            mid_x = width / 2\n",
    "\n",
    "            for table in tf.tables:\n",
    "                # Extraer contenido de tabla manejando None\n",
    "                table_data = []\n",
    "                for row in table.extract():\n",
    "                    cleaned_row = [str(cell) if cell is not None else \"\" for cell in row]\n",
    "                    table_data.append(\"|\".join(cleaned_row))\n",
    "\n",
    "                table_content = \"\\n\".join(table_data)\n",
    "                table_center = (table.bbox[0] + table.bbox[2]) / 2\n",
    "\n",
    "                # Determinar idioma por posición\n",
    "                if table_center < mid_x:\n",
    "                    valencia_content.append(f\"Tabla página {page_num+1}:\\n{table_content}\")\n",
    "                else:\n",
    "                    castellano_content.append(f\"Tabla página {page_num+1}:\\n{table_content}\")\n",
    "\n",
    "                table_bboxes.append(table.bbox)\n",
    "\n",
    "            # Procesar texto normal excluyendo tablas\n",
    "            words = page.extract_words()\n",
    "            non_table_words = [\n",
    "                word for word in words\n",
    "                if not any(\n",
    "                    (word['x0'] >= t[0] and word['x1'] <= t[2] and\n",
    "                    word['top'] >= t[1] and word['bottom'] <= t[3])\n",
    "                    for t in table_bboxes\n",
    "                )\n",
    "            ]\n",
    "\n",
    "            # Separar columnas con márgenes\n",
    "            left_col = []\n",
    "            right_col = []\n",
    "            for word in non_table_words:\n",
    "                word_center = (word['x0'] + word['x1']) / 2\n",
    "                if word_center < mid_x - 15:\n",
    "                    left_col.append(word)\n",
    "                elif word_center > mid_x + 15:\n",
    "                    right_col.append(word)\n",
    "\n",
    "            # Construir textos\n",
    "            def build_text(col_words):\n",
    "                return \" \".join([w['text'] for w in sorted(col_words, key=lambda x: (x['top'], x['x0']))])\n",
    "\n",
    "            valencia_content.append(build_text(left_col))\n",
    "            castellano_content.append(build_text(right_col))\n",
    "\n",
    "    # Crear documentos finales por idioma\n",
    "    return [\n",
    "        Document(\n",
    "            page_content=\"\\n\\n\".join(valencia_content),\n",
    "            metadata={\"source\": file_path, \"language\": \"valencia\"}\n",
    "        ),\n",
    "        Document(\n",
    "            page_content=\"\\n\\n\".join(castellano_content),\n",
    "            metadata={\"source\": file_path, \"language\": \"castellano\"}\n",
    "        )\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/content/drive/My Drive/clase 3 carrera/PROY3/Archivos/U0957354.pdf\"\n",
    "documents = await load_pdf_by_language(file_path)\n",
    "\n",
    "# Acceder a los documentos por idioma\n",
    "doc_valencia = documents[0]\n",
    "doc_castellano = documents[1]\n",
    "\n",
    "print(f\"Contenido en Valenciano ({len(doc_valencia.page_content)} caracteres):\")\n",
    "print(json.dumps(doc_valencia, indent=4, default=lambda o: o.__dict__))\n",
    "print(f\"\\nContenido en Castellano ({len(doc_castellano.page_content)} caracteres):\")\n",
    "print(json.dumps(doc_castellano, indent=4, default=lambda o: o.__dict__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ojeem\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Sistema RAG inicializado correctamente\n"
     ]
    }
   ],
   "source": [
    "from rag_functions import RAGSystem\n",
    "rag = RAGSystem()\n",
    "print(\"✅ Sistema RAG inicializado correctamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Selecciona un archivo PDF para procesar\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pdfplumber\n",
    "import traceback\n",
    "from tkinter import Tk, filedialog\n",
    "from IPython.display import display, FileLink\n",
    "\n",
    "def seleccionar_archivo():\n",
    "    \"\"\"Abre un diálogo para seleccionar archivo PDF\"\"\"\n",
    "    root = Tk()\n",
    "    root.withdraw()  # Ocultar la ventana principal\n",
    "    root.wm_attributes('-topmost', 1)  # Mantener la ventana encima de otras\n",
    "    archivo = filedialog.askopenfilename(\n",
    "        title=\"Selecciona un archivo PDF\",\n",
    "        filetypes=[(\"Archivos PDF\", \"*.pdf\"), (\"Todos los archivos\", \"*.*\")]\n",
    "    )\n",
    "    return archivo\n",
    "\n",
    "def es_documento_bilingue(texto):\n",
    "    \"\"\"Detecta si el documento es bilingüe castellano/valenciano\"\"\"\n",
    "    lineas = texto.split('\\n')\n",
    "    if len(lineas) < 2:\n",
    "        return False\n",
    "    \n",
    "    palabras_valenciano = {'valencià', 'valenciana', 'nosaltres', 'vosaltres', 'davant', 'ací'}\n",
    "    palabras_castellano = {'castellano', 'español', 'nosotros', 'vosotros', 'delante', 'aquí'}\n",
    "    \n",
    "    muestras = min(20, len(lineas)//2)\n",
    "    detecciones_val = 0\n",
    "    detecciones_cast = 0\n",
    "    \n",
    "    for i in range(muestras):\n",
    "        linea_cast = lineas[i*2].lower()\n",
    "        linea_val = lineas[i*2+1].lower() if i*2+1 < len(lineas) else \"\"\n",
    "        \n",
    "        if any(pal in linea_cast for pal in palabras_castellano):\n",
    "            detecciones_cast += 1\n",
    "        if any(pal in linea_val for pal in palabras_valenciano):\n",
    "            detecciones_val += 1\n",
    "    \n",
    "    return detecciones_val > muestras/2 and detecciones_cast > muestras/2\n",
    "\n",
    "def dividir_tabla_bilingue(tabla):\n",
    "    \"\"\"Divide una tabla bilingüe en castellano y valenciano\"\"\"\n",
    "    tabla_cast = []\n",
    "    tabla_val = []\n",
    "    \n",
    "    for fila in tabla:\n",
    "        fila_cast = []\n",
    "        fila_val = []\n",
    "        for celda in fila:\n",
    "            partes = str(celda).split('\\n')\n",
    "            fila_cast.append(partes[0] if len(partes) > 0 else \"\")\n",
    "            fila_val.append(partes[1] if len(partes) > 1 else partes[0] if len(partes) > 0 else \"\")\n",
    "        \n",
    "        tabla_cast.append(fila_cast)\n",
    "        tabla_val.append(fila_val)\n",
    "    \n",
    "    return tabla_cast, tabla_val\n",
    "\n",
    "def procesar_pdf(pdf_path):\n",
    "    \"\"\"Procesa el PDF y devuelve los resultados\"\"\"\n",
    "    try:\n",
    "        if not pdf_path or not os.path.exists(pdf_path):\n",
    "            raise FileNotFoundError(f\"El archivo {pdf_path} no existe o no se especificó\")\n",
    "        \n",
    "        if not pdf_path.lower().endswith('.pdf'):\n",
    "            raise ValueError(\"El archivo debe ser un PDF (extensión .pdf)\")\n",
    "        \n",
    "        texto_completo = \"\"\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            for page in pdf.pages:\n",
    "                texto = page.extract_text()\n",
    "                if texto:\n",
    "                    texto_completo += texto + \"\\n\"\n",
    "        \n",
    "        es_bilingue = es_documento_bilingue(texto_completo)\n",
    "        resultados = {\n",
    "            \"archivo\": pdf_path,\n",
    "            \"es_bilingue\": es_bilingue,\n",
    "            \"tablas_castellano\": [],\n",
    "            \"tablas_valenciano\": [],\n",
    "            \"texto_castellano\": \"\",\n",
    "            \"texto_valenciano\": \"\",\n",
    "            \"error\": None\n",
    "        }\n",
    "        \n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            for page in pdf.pages:\n",
    "                tables = page.extract_tables()\n",
    "                for table in tables:\n",
    "                    if len(table) > 1:\n",
    "                        if es_bilingue:\n",
    "                            tabla_cast, tabla_val = dividir_tabla_bilingue(table)\n",
    "                            df_cast = pd.DataFrame(tabla_cast[1:], columns=tabla_cast[0])\n",
    "                            df_val = pd.DataFrame(tabla_val[1:], columns=tabla_val[0])\n",
    "                            resultados[\"tablas_castellano\"].append(df_cast)\n",
    "                            resultados[\"tablas_valenciano\"].append(df_val)\n",
    "                        else:\n",
    "                            df = pd.DataFrame(table[1:], columns=table[0])\n",
    "                            resultados[\"tablas_castellano\"].append(df)\n",
    "            \n",
    "            if not resultados[\"tablas_castellano\"]:\n",
    "                lineas = texto_completo.split('\\n')\n",
    "                if es_bilingue:\n",
    "                    resultados[\"texto_castellano\"] = \"\\n\".join(lineas[::2])\n",
    "                    resultados[\"texto_valenciano\"] = \"\\n\".join(lineas[1::2])\n",
    "                else:\n",
    "                    resultados[\"texto_castellano\"] = texto_completo\n",
    "        \n",
    "        return resultados\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"archivo\": pdf_path,\n",
    "            \"error\": str(e),\n",
    "            \"traceback\": traceback.format_exc()\n",
    "        }\n",
    "\n",
    "def guardar_resultados(resultados):\n",
    "    \"\"\"Guarda los resultados en el mismo directorio que el PDF\"\"\"\n",
    "    if resultados.get(\"error\"):\n",
    "        return\n",
    "    \n",
    "    directorio = os.path.dirname(resultados[\"archivo\"])\n",
    "    nombre_base = os.path.splitext(os.path.basename(resultados[\"archivo\"]))[0]\n",
    "    archivos_creados = []\n",
    "    \n",
    "    # Guardar tablas\n",
    "    for i, tabla in enumerate(resultados[\"tablas_castellano\"], 1):\n",
    "        archivo_cast = os.path.join(directorio, f\"{nombre_base}_tabla_{i}_cast.csv\")\n",
    "        tabla.to_csv(archivo_cast, index=False, encoding='utf-8-sig')\n",
    "        archivos_creados.append(archivo_cast)\n",
    "        \n",
    "        if resultados[\"es_bilingue\"]:\n",
    "            archivo_val = os.path.join(directorio, f\"{nombre_base}_tabla_{i}_val.csv\")\n",
    "            resultados[\"tablas_valenciano\"][i-1].to_csv(archivo_val, index=False, encoding='utf-8-sig')\n",
    "            archivos_creados.append(archivo_val)\n",
    "    \n",
    "    # Guardar texto\n",
    "    archivo_cast = os.path.join(directorio, f\"{nombre_base}_cast.txt\")\n",
    "    with open(archivo_cast, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(resultados[\"texto_castellano\"])\n",
    "    archivos_creados.append(archivo_cast)\n",
    "    \n",
    "    if resultados[\"es_bilingue\"]:\n",
    "        archivo_val = os.path.join(directorio, f\"{nombre_base}_val.txt\")\n",
    "        with open(archivo_val, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(resultados[\"texto_valenciano\"])\n",
    "        archivos_creados.append(archivo_val)\n",
    "    \n",
    "    return archivos_creados\n",
    "\n",
    "# Versión para Jupyter Notebook\n",
    "def procesar_pdf_interactivo():\n",
    "    \"\"\"Versión interactiva para Jupyter Notebook\"\"\"\n",
    "    print(\"🔍 Selecciona un archivo PDF para procesar\")\n",
    "    pdf_path = seleccionar_archivo()\n",
    "    \n",
    "    if not pdf_path:\n",
    "        print(\"❌ No se seleccionó ningún archivo\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\n📄 Procesando archivo: {os.path.basename(pdf_path)}\")\n",
    "    \n",
    "    resultados = procesar_pdf(pdf_path)\n",
    "    \n",
    "    if resultados.get(\"error\"):\n",
    "        print(f\"\\n❌ Error al procesar el archivo:\")\n",
    "        print(resultados[\"error\"])\n",
    "    else:\n",
    "        archivos_creados = guardar_resultados(resultados)\n",
    "        \n",
    "        print(\"\\n✅ Procesamiento completado:\")\n",
    "        print(f\"- Documento {'bilingüe' if resultados['es_bilingue'] else 'monolingüe'}\")\n",
    "        \n",
    "        if resultados[\"tablas_castellano\"]:\n",
    "            print(f\"- {len(resultados['tablas_castellano'])} tablas encontradas\")\n",
    "        else:\n",
    "            print(\"- Texto extraído (sin tablas)\")\n",
    "        \n",
    "        print(\"\\n📂 Archivos creados:\")\n",
    "        for archivo in archivos_creados:\n",
    "            display(FileLink(archivo, result_html_prefix=\"📄 \"))\n",
    "\n",
    "# Ejecutar en Jupyter Notebook\n",
    "procesar_pdf_interactivo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement database_faiss (from versions: none)\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: C:\\Users\\ojeem\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n",
      "ERROR: No matching distribution found for database_faiss\n"
     ]
    }
   ],
   "source": [
    "%pip install database_faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ojeem\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS inicializado - Vectores: 79044 | Dimensión: 768\n",
      "\n",
      "Pregunta: ¿Cuántas horas de docencia presencial tiene un crédito?\n",
      "Respuesta: {'query': '¿Cuántas horas de docencia presencial tiene un crédito?', 'context_used': '39052', 'response': 'No hay información suficiente para determinar el número de horas de docencia presencial que tiene un crédito.', 'contexts': [{'id': '39052', 'content': 'c. Número de horas de formación  realizadas  \\nhace dos años. \\n \\n                                                            \\n3 Es comptabilitzen  les hores de formació concedides  d’activitats  voluntàries  pertanyents  al Pla de \\nFormació;  les hores certificades  dels cursos d’autoformació  i de proves de certificació  de la Unitat de \\nFormació,  i les hores concedides  de les activitats externes,  així com les de formació fetes en el Centre de', 'score': np.float32(0.9164475)}, {'id': '10166', 'content': '- Descripció  de les accions que s’han de desenvolupar  (títol de l’activitat,  quantitat  d’hores, \\ndocent, lloc d’impartició,  modalitat  de formació…).  \\n- Col∙lectius, perfil del personal al qual va adreçada  l’acció i nombre total de places per cada \\nacció formativa.  \\n- Calendari  d’execució  previst per a cada una de les accions formatives.  \\n- Distribució  de la formació per als campus d’Alcoi, Gandia i València. \\n- Idioma d’impartició  de l’activitat.', 'score': np.float32(0.9252427)}, {'id': '40720', 'content': 'el crédito ECTS, que computa la dedicación  del \\nalumno, supondrá  una dedicación  reconocida  \\nmáxima del profesor de 12 horas. \\n De este CREP, 10 horas serán de actividad \\ndocente presencial  (clases organizadas  en sus \\ndiferentes  modalidades).  Por otra parte, el CREP \\nconstará además de 1 hora reconocida  por la \\nactividad de seguimiento  docente. El resto de \\nreconocimiento  de \\nla labor docente, hasta un \\nmáximo de 1 hora, quedará especificado  y', 'score': np.float32(0.9270414)}]}\n",
      "\n",
      "Pregunta: ¿Qué normativa regula el reconocimiento de horas?\n",
      "Respuesta: {'query': '¿Qué normativa regula el reconocimiento de horas?', 'context_used': '3471', 'response': 'No hay información suficiente en el contexto proporcionado para determinar específicamente qué normativa regula el reconocimiento de horas. El texto menciona varios reglamentos y normativas de órganos universitarios pero no aborda directamente el tema del reconocimiento de horas.', 'contexts': [{'id': '3471', 'content': 'expresa y excepcionalmente lo contrario.  \\n \\nLos reglamentos del Claustro, del Consejo de Gobierno, de los Centros, de los Departamentos, \\nde los Institutos Universitarios de Investigac ión y de las Estructuras Propias de Investigación, \\nasí como las normativas de creación de otros órganos colegiados regulan la constitución y \\ndesarrollo de las sesiones sin que con carácter general se determine de manera presencial o a \\ndistancia.', 'score': np.float32(1.0277586)}, {'id': '41138', 'content': 'L’article 7 del Reial decret 412/2014, de 6 de juny, pel qual s’estableix la normativa bàsica dels procediments d’admissió als ensenyaments universitaris oficials de grau, estableix la interven ció necessària de les universitats públiques en els criteris de \\nvaloració, les regles que s’hagen d’aplicar per a establir l’ordre de prelació en \\nl’adjudicació de places i, si s’escau, els procediments d’admissió.', 'score': np.float32(1.027792)}, {'id': '78693', 'content': \"forma expressa i excepcional.  \\n \\nEls reglaments del Claustre, del Consell de Govern, dels centres, dels departaments, dels \\ninstituts universitaris d'investigació i de les estructures pròpies d'investigació, així com les \\nnormatives de creació d'altres òrgans col·legiats, regulen la constitució i el desenvolupament \\nde les sessions sense que, amb caràcter general, es determinen de manera presencial o a \\ndistància.\", 'score': np.float32(1.0316381)}]}\n",
      "\n",
      "Pregunta: ¿Existe un máximo de horas no presenciales por crédito?\n",
      "Respuesta: {'query': '¿Existe un máximo de horas no presenciales por crédito?', 'context_used': '38394', 'response': 'No hay información suficiente en el contexto proporcionado para determinar si existe un máximo de horas no presenciales por crédito. El texto se refiere a jornadas laborales y obligaciones del personal con dedicación completa, pero no menciona específicamente horas no presenciales por crédito.', 'contexts': [{'id': '38394', 'content': '12.1.5.  En tot cas,  entre  el final  d’una jornada  i el començament  de la següent  hi ha \\nd’haver,  com a mínim,  dotze  hores.  \\n \\n12.1.6.  Són obligacions  del personal  amb  jornada  que té assignat  el complement  \\nespecífic  de dedicació  completa, les  següents:  \\n \\na. Respondre  al requeriment  per a fer una jornada  setmanal  superior  a la que  li \\ncorrespon  quan  les necessitats  urgents  del servei així ho exigeixen.', 'score': np.float32(0.9938213)}, {'id': '18793', 'content': '12.1.5.  En todo  caso,  entre  el final  de una jornada  y el comienzo  de la siguiente  mediarán,  \\ncomo  mínimo,  doce  horas.  \\n \\n12.1.6.  Son obligaciones  del personal  con jornada  que tenga  asignado  el complemento  \\nespecífico  de dedicación  completa, las  siguientes:  \\n \\na. Responder  al requerimiento  para  la realización  de una jornada  semanal  \\nsuperior  a la que le corresponde  cuando  las necesidades  urgentes  del servicio  así lo exijan.', 'score': np.float32(1.0086882)}, {'id': '39000', 'content': 'correcte de l’acció formativa,  sense \\nque no superen un màxim anual de \\ncinquanta  hores. \\n2. Impartides  en modalitat  en línia \\nasíncrona:  s’han de desenvolupar  \\nfora de la jornada laboral i no \\ncomputen  en el crèdit de les \\ncinquanta  hores esmentat.  \\n \\nc) Per a assistir a les accions formatives  \\nexternes que tenen relació amb el lloc de \\ntreball, es disposa d’una llicència de \\ncinquanta  hores de conformitat  amb el \\nque es disposa en l’apartat 8.1.a de la \\npresent normativa.', 'score': np.float32(1.0093118)}]}\n"
     ]
    }
   ],
   "source": [
    "# otro_script.py\n",
    "\n",
    "from poli_gpt import PoliGPT\n",
    "\n",
    "def main():\n",
    "    # Inicializar una vez\n",
    "    poligpt_client = PoliGPT()\n",
    "    \n",
    "    # Consultar múltiples veces\n",
    "    preguntas = [\n",
    "        \"¿Cuántas horas de docencia presencial tiene un crédito?\",\n",
    "        \"¿Qué normativa regula el reconocimiento de horas?\",\n",
    "        \"¿Existe un máximo de horas no presenciales por crédito?\"\n",
    "    ]\n",
    "    \n",
    "    for pregunta in preguntas:\n",
    "        respuesta = poligpt_client.query_poligpt(pregunta)\n",
    "        print(f\"\\nPregunta: {pregunta}\")\n",
    "        print(f\"Respuesta: {respuesta}\")\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
