{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import PyPDF2\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "pdf_folder = \"/content/drive/My Drive/clase 3 carrera/PROY3/Archivos/\"\n",
    "import pdfplumber\n",
    "from pdfplumber.table import TableFinder\n",
    "from langchain.schema import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def load_pdf_by_language(file_path: str) -> list[Document]:\n",
    "    \"\"\"\n",
    "    Carga un PDF separando contenido en valenciano y castellano,\n",
    "    agrupando todo el contenido por idioma en documentos únicos\n",
    "    \"\"\"\n",
    "    valencia_content = []\n",
    "    castellano_content = []\n",
    "\n",
    "    with pdfplumber.open(file_path) as pdf:\n",
    "        for page_num, page in enumerate(pdf.pages):\n",
    "            # Configuración para detección de tablas\n",
    "            table_settings = {\n",
    "                \"vertical_strategy\": \"lines\",\n",
    "                \"horizontal_strategy\": \"lines\",\n",
    "                \"snap_tolerance\": 4,\n",
    "                \"join_tolerance\": 10\n",
    "            }\n",
    "\n",
    "            # Procesar tablas primero\n",
    "            tf = TableFinder(page, table_settings)\n",
    "            table_bboxes = []\n",
    "            width = page.width\n",
    "            mid_x = width / 2\n",
    "\n",
    "            for table in tf.tables:\n",
    "                # Extraer contenido de tabla manejando None\n",
    "                table_data = []\n",
    "                for row in table.extract():\n",
    "                    cleaned_row = [str(cell) if cell is not None else \"\" for cell in row]\n",
    "                    table_data.append(\"|\".join(cleaned_row))\n",
    "\n",
    "                table_content = \"\\n\".join(table_data)\n",
    "                table_center = (table.bbox[0] + table.bbox[2]) / 2\n",
    "\n",
    "                # Determinar idioma por posición\n",
    "                if table_center < mid_x:\n",
    "                    valencia_content.append(f\"Tabla página {page_num+1}:\\n{table_content}\")\n",
    "                else:\n",
    "                    castellano_content.append(f\"Tabla página {page_num+1}:\\n{table_content}\")\n",
    "\n",
    "                table_bboxes.append(table.bbox)\n",
    "\n",
    "            # Procesar texto normal excluyendo tablas\n",
    "            words = page.extract_words()\n",
    "            non_table_words = [\n",
    "                word for word in words\n",
    "                if not any(\n",
    "                    (word['x0'] >= t[0] and word['x1'] <= t[2] and\n",
    "                    word['top'] >= t[1] and word['bottom'] <= t[3])\n",
    "                    for t in table_bboxes\n",
    "                )\n",
    "            ]\n",
    "\n",
    "            # Separar columnas con márgenes\n",
    "            left_col = []\n",
    "            right_col = []\n",
    "            for word in non_table_words:\n",
    "                word_center = (word['x0'] + word['x1']) / 2\n",
    "                if word_center < mid_x - 15:\n",
    "                    left_col.append(word)\n",
    "                elif word_center > mid_x + 15:\n",
    "                    right_col.append(word)\n",
    "\n",
    "            # Construir textos\n",
    "            def build_text(col_words):\n",
    "                return \" \".join([w['text'] for w in sorted(col_words, key=lambda x: (x['top'], x['x0']))])\n",
    "\n",
    "            valencia_content.append(build_text(left_col))\n",
    "            castellano_content.append(build_text(right_col))\n",
    "\n",
    "    # Crear documentos finales por idioma\n",
    "    return [\n",
    "        Document(\n",
    "            page_content=\"\\n\\n\".join(valencia_content),\n",
    "            metadata={\"source\": file_path, \"language\": \"valencia\"}\n",
    "        ),\n",
    "        Document(\n",
    "            page_content=\"\\n\\n\".join(castellano_content),\n",
    "            metadata={\"source\": file_path, \"language\": \"castellano\"}\n",
    "        )\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/content/drive/My Drive/clase 3 carrera/PROY3/Archivos/U0957354.pdf\"\n",
    "documents = await load_pdf_by_language(file_path)\n",
    "\n",
    "# Acceder a los documentos por idioma\n",
    "doc_valencia = documents[0]\n",
    "doc_castellano = documents[1]\n",
    "\n",
    "print(f\"Contenido en Valenciano ({len(doc_valencia.page_content)} caracteres):\")\n",
    "print(json.dumps(doc_valencia, indent=4, default=lambda o: o.__dict__))\n",
    "print(f\"\\nContenido en Castellano ({len(doc_castellano.page_content)} caracteres):\")\n",
    "print(json.dumps(doc_castellano, indent=4, default=lambda o: o.__dict__))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
