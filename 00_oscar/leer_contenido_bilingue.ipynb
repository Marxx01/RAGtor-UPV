{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import PyPDF2\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "pdf_folder = \"/content/drive/My Drive/clase 3 carrera/PROY3/Archivos/\"\n",
    "import pdfplumber\n",
    "from pdfplumber.table import TableFinder\n",
    "from langchain.schema import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cpu\n",
      "Collecting torch==2.0.1\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torch-2.0.1%2Bcpu-cp311-cp311-win_amd64.whl (174.0 MB)\n",
      "     ---------------------------------------- 0.0/174.0 MB ? eta -:--:--\n",
      "     --------------------------------------- 2.1/174.0 MB 11.8 MB/s eta 0:00:15\n",
      "      -------------------------------------- 4.5/174.0 MB 11.7 MB/s eta 0:00:15\n",
      "     - ------------------------------------- 7.1/174.0 MB 11.8 MB/s eta 0:00:15\n",
      "     -- ------------------------------------ 9.7/174.0 MB 11.6 MB/s eta 0:00:15\n",
      "     -- ----------------------------------- 12.3/174.0 MB 11.7 MB/s eta 0:00:14\n",
      "     --- ---------------------------------- 14.7/174.0 MB 11.7 MB/s eta 0:00:14\n",
      "     --- ---------------------------------- 17.3/174.0 MB 11.7 MB/s eta 0:00:14\n",
      "     ---- --------------------------------- 19.9/174.0 MB 11.6 MB/s eta 0:00:14\n",
      "     ---- --------------------------------- 22.3/174.0 MB 11.6 MB/s eta 0:00:14\n",
      "     ----- -------------------------------- 24.9/174.0 MB 11.7 MB/s eta 0:00:13\n",
      "     ----- -------------------------------- 27.3/174.0 MB 11.7 MB/s eta 0:00:13\n",
      "     ------ ------------------------------- 29.6/174.0 MB 11.7 MB/s eta 0:00:13\n",
      "     ------ ------------------------------- 32.0/174.0 MB 11.7 MB/s eta 0:00:13\n",
      "     ------- ------------------------------ 34.6/174.0 MB 11.7 MB/s eta 0:00:12\n",
      "     -------- ----------------------------- 37.0/174.0 MB 11.7 MB/s eta 0:00:12\n",
      "     -------- ----------------------------- 39.6/174.0 MB 11.7 MB/s eta 0:00:12\n",
      "     --------- ---------------------------- 41.9/174.0 MB 11.7 MB/s eta 0:00:12\n",
      "     --------- ---------------------------- 44.3/174.0 MB 11.7 MB/s eta 0:00:12\n",
      "     ---------- --------------------------- 46.9/174.0 MB 11.7 MB/s eta 0:00:11\n",
      "     ---------- --------------------------- 49.5/174.0 MB 11.7 MB/s eta 0:00:11\n",
      "     ----------- -------------------------- 51.9/174.0 MB 11.7 MB/s eta 0:00:11\n",
      "     ----------- -------------------------- 54.3/174.0 MB 11.6 MB/s eta 0:00:11\n",
      "     ------------ ------------------------- 56.6/174.0 MB 11.7 MB/s eta 0:00:11\n",
      "     ------------ ------------------------- 59.0/174.0 MB 11.7 MB/s eta 0:00:10\n",
      "     ------------- ------------------------ 61.6/174.0 MB 11.7 MB/s eta 0:00:10\n",
      "     ------------- ------------------------ 64.0/174.0 MB 11.7 MB/s eta 0:00:10\n",
      "     -------------- ----------------------- 66.3/174.0 MB 11.6 MB/s eta 0:00:10\n",
      "     -------------- ----------------------- 68.7/174.0 MB 11.6 MB/s eta 0:00:10\n",
      "     --------------- ---------------------- 71.0/174.0 MB 11.6 MB/s eta 0:00:09\n",
      "     ---------------- --------------------- 73.4/174.0 MB 11.7 MB/s eta 0:00:09\n",
      "     ---------------- --------------------- 76.0/174.0 MB 11.7 MB/s eta 0:00:09\n",
      "     ----------------- -------------------- 78.4/174.0 MB 11.7 MB/s eta 0:00:09\n",
      "     ----------------- -------------------- 80.7/174.0 MB 11.6 MB/s eta 0:00:09\n",
      "     ------------------ ------------------- 83.4/174.0 MB 11.6 MB/s eta 0:00:08\n",
      "     ------------------ ------------------- 86.0/174.0 MB 11.6 MB/s eta 0:00:08\n",
      "     ------------------- ------------------ 88.3/174.0 MB 11.6 MB/s eta 0:00:08\n",
      "     ------------------- ------------------ 90.7/174.0 MB 11.6 MB/s eta 0:00:08\n",
      "     -------------------- ----------------- 93.1/174.0 MB 11.6 MB/s eta 0:00:07\n",
      "     -------------------- ----------------- 95.7/174.0 MB 11.7 MB/s eta 0:00:07\n",
      "     --------------------- ---------------- 98.0/174.0 MB 11.7 MB/s eta 0:00:07\n",
      "     --------------------- --------------- 100.7/174.0 MB 11.6 MB/s eta 0:00:07\n",
      "     --------------------- --------------- 103.0/174.0 MB 11.6 MB/s eta 0:00:07\n",
      "     ---------------------- -------------- 105.6/174.0 MB 11.6 MB/s eta 0:00:06\n",
      "     ----------------------- ------------- 108.3/174.0 MB 11.7 MB/s eta 0:00:06\n",
      "     ----------------------- ------------- 110.6/174.0 MB 11.7 MB/s eta 0:00:06\n",
      "     ------------------------ ------------ 113.2/174.0 MB 11.7 MB/s eta 0:00:06\n",
      "     ------------------------ ------------ 115.6/174.0 MB 11.7 MB/s eta 0:00:06\n",
      "     ------------------------- ----------- 118.0/174.0 MB 11.7 MB/s eta 0:00:05\n",
      "     ------------------------- ----------- 120.3/174.0 MB 11.7 MB/s eta 0:00:05\n",
      "     -------------------------- ---------- 122.9/174.0 MB 11.6 MB/s eta 0:00:05\n",
      "     -------------------------- ---------- 125.3/174.0 MB 11.7 MB/s eta 0:00:05\n",
      "     --------------------------- --------- 127.9/174.0 MB 11.7 MB/s eta 0:00:04\n",
      "     --------------------------- --------- 130.3/174.0 MB 11.7 MB/s eta 0:00:04\n",
      "     ---------------------------- -------- 132.9/174.0 MB 11.7 MB/s eta 0:00:04\n",
      "     ---------------------------- -------- 135.3/174.0 MB 11.7 MB/s eta 0:00:04\n",
      "     ----------------------------- ------- 137.6/174.0 MB 11.6 MB/s eta 0:00:04\n",
      "     ----------------------------- ------- 140.2/174.0 MB 11.7 MB/s eta 0:00:03\n",
      "     ------------------------------ ------ 142.9/174.0 MB 11.7 MB/s eta 0:00:03\n",
      "     ------------------------------ ------ 145.2/174.0 MB 11.7 MB/s eta 0:00:03\n",
      "     ------------------------------- ----- 147.6/174.0 MB 11.7 MB/s eta 0:00:03\n",
      "     ------------------------------- ----- 150.5/174.0 MB 11.6 MB/s eta 0:00:03\n",
      "     -------------------------------- ---- 152.8/174.0 MB 11.6 MB/s eta 0:00:02\n",
      "     --------------------------------- --- 155.5/174.0 MB 11.6 MB/s eta 0:00:02\n",
      "     --------------------------------- --- 157.8/174.0 MB 11.6 MB/s eta 0:00:02\n",
      "     ---------------------------------- -- 160.2/174.0 MB 11.6 MB/s eta 0:00:02\n",
      "     ---------------------------------- -- 162.8/174.0 MB 11.6 MB/s eta 0:00:01\n",
      "     ----------------------------------- - 165.4/174.0 MB 11.6 MB/s eta 0:00:01\n",
      "     ----------------------------------- - 168.0/174.0 MB 11.6 MB/s eta 0:00:01\n",
      "     ------------------------------------  170.4/174.0 MB 11.6 MB/s eta 0:00:01\n",
      "     ------------------------------------  172.8/174.0 MB 11.6 MB/s eta 0:00:01\n",
      "     ------------------------------------  173.8/174.0 MB 11.6 MB/s eta 0:00:01\n",
      "     ------------------------------------  173.8/174.0 MB 11.6 MB/s eta 0:00:01\n",
      "     ------------------------------------- 174.0/174.0 MB 11.3 MB/s eta 0:00:00\n",
      "Collecting torchvision==0.15.2\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torchvision-0.15.2%2Bcpu-cp311-cp311-win_amd64.whl (1.2 MB)\n",
      "     ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "     ---------------------------------------- 1.2/1.2 MB 7.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: filelock in c:\\users\\ojeem\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch==2.0.1) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\ojeem\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch==2.0.1) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\ojeem\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch==2.0.1) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\ojeem\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch==2.0.1) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ojeem\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch==2.0.1) (3.1.6)\n",
      "Requirement already satisfied: numpy in c:\\users\\ojeem\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torchvision==0.15.2) (2.2.4)\n",
      "Requirement already satisfied: requests in c:\\users\\ojeem\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torchvision==0.15.2) (2.32.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\ojeem\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torchvision==0.15.2) (11.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ojeem\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jinja2->torch==2.0.1) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ojeem\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->torchvision==0.15.2) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ojeem\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->torchvision==0.15.2) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ojeem\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->torchvision==0.15.2) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ojeem\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->torchvision==0.15.2) (2025.1.31)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\ojeem\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sympy->torch==2.0.1) (1.3.0)\n",
      "Installing collected packages: torch, torchvision\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.7.0\n",
      "    Uninstalling torch-2.7.0:\n",
      "      Successfully uninstalled torch-2.7.0\n",
      "Successfully installed torch-2.0.1+cpu torchvision-0.15.2+cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: C:\\Users\\ojeem\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==2.0.1 torchvision==0.15.2 --index-url https://download.pytorch.org/whl/cpu "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Torch: 2.0.1+cpu\n",
      "‚úÖ TorchVision: 0.15.2+cpu\n",
      "üî• ¬°NMS funciona correctamente!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "print(f\"‚úÖ Torch: {torch.__version__}\")\n",
    "print(f\"‚úÖ TorchVision: {torchvision.__version__}\")\n",
    "\n",
    "from torchvision.ops import nms\n",
    "print(\"üî• ¬°NMS funciona correctamente!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def load_pdf_by_language(file_path: str) -> list[Document]:\n",
    "    \"\"\"\n",
    "    Carga un PDF separando contenido en valenciano y castellano,\n",
    "    agrupando todo el contenido por idioma en documentos √∫nicos\n",
    "    \"\"\"\n",
    "    valencia_content = []\n",
    "    castellano_content = []\n",
    "\n",
    "    with pdfplumber.open(file_path) as pdf:\n",
    "        for page_num, page in enumerate(pdf.pages):\n",
    "            # Configuraci√≥n para detecci√≥n de tablas\n",
    "            table_settings = {\n",
    "                \"vertical_strategy\": \"lines\",\n",
    "                \"horizontal_strategy\": \"lines\",\n",
    "                \"snap_tolerance\": 4,\n",
    "                \"join_tolerance\": 10\n",
    "            }\n",
    "\n",
    "            # Procesar tablas primero\n",
    "            tf = TableFinder(page, table_settings)\n",
    "            table_bboxes = []\n",
    "            width = page.width\n",
    "            mid_x = width / 2\n",
    "\n",
    "            for table in tf.tables:\n",
    "                # Extraer contenido de tabla manejando None\n",
    "                table_data = []\n",
    "                for row in table.extract():\n",
    "                    cleaned_row = [str(cell) if cell is not None else \"\" for cell in row]\n",
    "                    table_data.append(\"|\".join(cleaned_row))\n",
    "\n",
    "                table_content = \"\\n\".join(table_data)\n",
    "                table_center = (table.bbox[0] + table.bbox[2]) / 2\n",
    "\n",
    "                # Determinar idioma por posici√≥n\n",
    "                if table_center < mid_x:\n",
    "                    valencia_content.append(f\"Tabla p√°gina {page_num+1}:\\n{table_content}\")\n",
    "                else:\n",
    "                    castellano_content.append(f\"Tabla p√°gina {page_num+1}:\\n{table_content}\")\n",
    "\n",
    "                table_bboxes.append(table.bbox)\n",
    "\n",
    "            # Procesar texto normal excluyendo tablas\n",
    "            words = page.extract_words()\n",
    "            non_table_words = [\n",
    "                word for word in words\n",
    "                if not any(\n",
    "                    (word['x0'] >= t[0] and word['x1'] <= t[2] and\n",
    "                    word['top'] >= t[1] and word['bottom'] <= t[3])\n",
    "                    for t in table_bboxes\n",
    "                )\n",
    "            ]\n",
    "\n",
    "            # Separar columnas con m√°rgenes\n",
    "            left_col = []\n",
    "            right_col = []\n",
    "            for word in non_table_words:\n",
    "                word_center = (word['x0'] + word['x1']) / 2\n",
    "                if word_center < mid_x - 15:\n",
    "                    left_col.append(word)\n",
    "                elif word_center > mid_x + 15:\n",
    "                    right_col.append(word)\n",
    "\n",
    "            # Construir textos\n",
    "            def build_text(col_words):\n",
    "                return \" \".join([w['text'] for w in sorted(col_words, key=lambda x: (x['top'], x['x0']))])\n",
    "\n",
    "            valencia_content.append(build_text(left_col))\n",
    "            castellano_content.append(build_text(right_col))\n",
    "\n",
    "    # Crear documentos finales por idioma\n",
    "    return [\n",
    "        Document(\n",
    "            page_content=\"\\n\\n\".join(valencia_content),\n",
    "            metadata={\"source\": file_path, \"language\": \"valencia\"}\n",
    "        ),\n",
    "        Document(\n",
    "            page_content=\"\\n\\n\".join(castellano_content),\n",
    "            metadata={\"source\": file_path, \"language\": \"castellano\"}\n",
    "        )\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/content/drive/My Drive/clase 3 carrera/PROY3/Archivos/U0957354.pdf\"\n",
    "documents = await load_pdf_by_language(file_path)\n",
    "\n",
    "# Acceder a los documentos por idioma\n",
    "doc_valencia = documents[0]\n",
    "doc_castellano = documents[1]\n",
    "\n",
    "print(f\"Contenido en Valenciano ({len(doc_valencia.page_content)} caracteres):\")\n",
    "print(json.dumps(doc_valencia, indent=4, default=lambda o: o.__dict__))\n",
    "print(f\"\\nContenido en Castellano ({len(doc_castellano.page_content)} caracteres):\")\n",
    "print(json.dumps(doc_castellano, indent=4, default=lambda o: o.__dict__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ojeem\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Sistema RAG inicializado correctamente\n"
     ]
    }
   ],
   "source": [
    "from rag_functions import RAGSystem\n",
    "rag = RAGSystem()\n",
    "print(\"‚úÖ Sistema RAG inicializado correctamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Selecciona un archivo PDF para procesar\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pdfplumber\n",
    "import traceback\n",
    "from tkinter import Tk, filedialog\n",
    "from IPython.display import display, FileLink\n",
    "\n",
    "def seleccionar_archivo():\n",
    "    \"\"\"Abre un di√°logo para seleccionar archivo PDF\"\"\"\n",
    "    root = Tk()\n",
    "    root.withdraw()  # Ocultar la ventana principal\n",
    "    root.wm_attributes('-topmost', 1)  # Mantener la ventana encima de otras\n",
    "    archivo = filedialog.askopenfilename(\n",
    "        title=\"Selecciona un archivo PDF\",\n",
    "        filetypes=[(\"Archivos PDF\", \"*.pdf\"), (\"Todos los archivos\", \"*.*\")]\n",
    "    )\n",
    "    return archivo\n",
    "\n",
    "def es_documento_bilingue(texto):\n",
    "    \"\"\"Detecta si el documento es biling√ºe castellano/valenciano\"\"\"\n",
    "    lineas = texto.split('\\n')\n",
    "    if len(lineas) < 2:\n",
    "        return False\n",
    "    \n",
    "    palabras_valenciano = {'valenci√†', 'valenciana', 'nosaltres', 'vosaltres', 'davant', 'ac√≠'}\n",
    "    palabras_castellano = {'castellano', 'espa√±ol', 'nosotros', 'vosotros', 'delante', 'aqu√≠'}\n",
    "    \n",
    "    muestras = min(20, len(lineas)//2)\n",
    "    detecciones_val = 0\n",
    "    detecciones_cast = 0\n",
    "    \n",
    "    for i in range(muestras):\n",
    "        linea_cast = lineas[i*2].lower()\n",
    "        linea_val = lineas[i*2+1].lower() if i*2+1 < len(lineas) else \"\"\n",
    "        \n",
    "        if any(pal in linea_cast for pal in palabras_castellano):\n",
    "            detecciones_cast += 1\n",
    "        if any(pal in linea_val for pal in palabras_valenciano):\n",
    "            detecciones_val += 1\n",
    "    \n",
    "    return detecciones_val > muestras/2 and detecciones_cast > muestras/2\n",
    "\n",
    "def dividir_tabla_bilingue(tabla):\n",
    "    \"\"\"Divide una tabla biling√ºe en castellano y valenciano\"\"\"\n",
    "    tabla_cast = []\n",
    "    tabla_val = []\n",
    "    \n",
    "    for fila in tabla:\n",
    "        fila_cast = []\n",
    "        fila_val = []\n",
    "        for celda in fila:\n",
    "            partes = str(celda).split('\\n')\n",
    "            fila_cast.append(partes[0] if len(partes) > 0 else \"\")\n",
    "            fila_val.append(partes[1] if len(partes) > 1 else partes[0] if len(partes) > 0 else \"\")\n",
    "        \n",
    "        tabla_cast.append(fila_cast)\n",
    "        tabla_val.append(fila_val)\n",
    "    \n",
    "    return tabla_cast, tabla_val\n",
    "\n",
    "def procesar_pdf(pdf_path):\n",
    "    \"\"\"Procesa el PDF y devuelve los resultados\"\"\"\n",
    "    try:\n",
    "        if not pdf_path or not os.path.exists(pdf_path):\n",
    "            raise FileNotFoundError(f\"El archivo {pdf_path} no existe o no se especific√≥\")\n",
    "        \n",
    "        if not pdf_path.lower().endswith('.pdf'):\n",
    "            raise ValueError(\"El archivo debe ser un PDF (extensi√≥n .pdf)\")\n",
    "        \n",
    "        texto_completo = \"\"\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            for page in pdf.pages:\n",
    "                texto = page.extract_text()\n",
    "                if texto:\n",
    "                    texto_completo += texto + \"\\n\"\n",
    "        \n",
    "        es_bilingue = es_documento_bilingue(texto_completo)\n",
    "        resultados = {\n",
    "            \"archivo\": pdf_path,\n",
    "            \"es_bilingue\": es_bilingue,\n",
    "            \"tablas_castellano\": [],\n",
    "            \"tablas_valenciano\": [],\n",
    "            \"texto_castellano\": \"\",\n",
    "            \"texto_valenciano\": \"\",\n",
    "            \"error\": None\n",
    "        }\n",
    "        \n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            for page in pdf.pages:\n",
    "                tables = page.extract_tables()\n",
    "                for table in tables:\n",
    "                    if len(table) > 1:\n",
    "                        if es_bilingue:\n",
    "                            tabla_cast, tabla_val = dividir_tabla_bilingue(table)\n",
    "                            df_cast = pd.DataFrame(tabla_cast[1:], columns=tabla_cast[0])\n",
    "                            df_val = pd.DataFrame(tabla_val[1:], columns=tabla_val[0])\n",
    "                            resultados[\"tablas_castellano\"].append(df_cast)\n",
    "                            resultados[\"tablas_valenciano\"].append(df_val)\n",
    "                        else:\n",
    "                            df = pd.DataFrame(table[1:], columns=table[0])\n",
    "                            resultados[\"tablas_castellano\"].append(df)\n",
    "            \n",
    "            if not resultados[\"tablas_castellano\"]:\n",
    "                lineas = texto_completo.split('\\n')\n",
    "                if es_bilingue:\n",
    "                    resultados[\"texto_castellano\"] = \"\\n\".join(lineas[::2])\n",
    "                    resultados[\"texto_valenciano\"] = \"\\n\".join(lineas[1::2])\n",
    "                else:\n",
    "                    resultados[\"texto_castellano\"] = texto_completo\n",
    "        \n",
    "        return resultados\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"archivo\": pdf_path,\n",
    "            \"error\": str(e),\n",
    "            \"traceback\": traceback.format_exc()\n",
    "        }\n",
    "\n",
    "def guardar_resultados(resultados):\n",
    "    \"\"\"Guarda los resultados en el mismo directorio que el PDF\"\"\"\n",
    "    if resultados.get(\"error\"):\n",
    "        return\n",
    "    \n",
    "    directorio = os.path.dirname(resultados[\"archivo\"])\n",
    "    nombre_base = os.path.splitext(os.path.basename(resultados[\"archivo\"]))[0]\n",
    "    archivos_creados = []\n",
    "    \n",
    "    # Guardar tablas\n",
    "    for i, tabla in enumerate(resultados[\"tablas_castellano\"], 1):\n",
    "        archivo_cast = os.path.join(directorio, f\"{nombre_base}_tabla_{i}_cast.csv\")\n",
    "        tabla.to_csv(archivo_cast, index=False, encoding='utf-8-sig')\n",
    "        archivos_creados.append(archivo_cast)\n",
    "        \n",
    "        if resultados[\"es_bilingue\"]:\n",
    "            archivo_val = os.path.join(directorio, f\"{nombre_base}_tabla_{i}_val.csv\")\n",
    "            resultados[\"tablas_valenciano\"][i-1].to_csv(archivo_val, index=False, encoding='utf-8-sig')\n",
    "            archivos_creados.append(archivo_val)\n",
    "    \n",
    "    # Guardar texto\n",
    "    archivo_cast = os.path.join(directorio, f\"{nombre_base}_cast.txt\")\n",
    "    with open(archivo_cast, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(resultados[\"texto_castellano\"])\n",
    "    archivos_creados.append(archivo_cast)\n",
    "    \n",
    "    if resultados[\"es_bilingue\"]:\n",
    "        archivo_val = os.path.join(directorio, f\"{nombre_base}_val.txt\")\n",
    "        with open(archivo_val, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(resultados[\"texto_valenciano\"])\n",
    "        archivos_creados.append(archivo_val)\n",
    "    \n",
    "    return archivos_creados\n",
    "\n",
    "# Versi√≥n para Jupyter Notebook\n",
    "def procesar_pdf_interactivo():\n",
    "    \"\"\"Versi√≥n interactiva para Jupyter Notebook\"\"\"\n",
    "    print(\"üîç Selecciona un archivo PDF para procesar\")\n",
    "    pdf_path = seleccionar_archivo()\n",
    "    \n",
    "    if not pdf_path:\n",
    "        print(\"‚ùå No se seleccion√≥ ning√∫n archivo\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\nüìÑ Procesando archivo: {os.path.basename(pdf_path)}\")\n",
    "    \n",
    "    resultados = procesar_pdf(pdf_path)\n",
    "    \n",
    "    if resultados.get(\"error\"):\n",
    "        print(f\"\\n‚ùå Error al procesar el archivo:\")\n",
    "        print(resultados[\"error\"])\n",
    "    else:\n",
    "        archivos_creados = guardar_resultados(resultados)\n",
    "        \n",
    "        print(\"\\n‚úÖ Procesamiento completado:\")\n",
    "        print(f\"- Documento {'biling√ºe' if resultados['es_bilingue'] else 'monoling√ºe'}\")\n",
    "        \n",
    "        if resultados[\"tablas_castellano\"]:\n",
    "            print(f\"- {len(resultados['tablas_castellano'])} tablas encontradas\")\n",
    "        else:\n",
    "            print(\"- Texto extra√≠do (sin tablas)\")\n",
    "        \n",
    "        print(\"\\nüìÇ Archivos creados:\")\n",
    "        for archivo in archivos_creados:\n",
    "            display(FileLink(archivo, result_html_prefix=\"üìÑ \"))\n",
    "\n",
    "# Ejecutar en Jupyter Notebook\n",
    "procesar_pdf_interactivo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement database_faiss (from versions: none)\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: C:\\Users\\ojeem\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n",
      "ERROR: No matching distribution found for database_faiss\n"
     ]
    }
   ],
   "source": [
    "%pip install database_faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ojeem\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS inicializado - Vectores: 79044 | Dimensi√≥n: 768\n",
      "\n",
      "Pregunta: ¬øCu√°ntas horas de docencia presencial tiene un cr√©dito?\n",
      "Respuesta: {'query': '¬øCu√°ntas horas de docencia presencial tiene un cr√©dito?', 'context_used': '39052', 'response': 'No hay informaci√≥n suficiente para determinar el n√∫mero de horas de docencia presencial que tiene un cr√©dito.', 'contexts': [{'id': '39052', 'content': 'c. N√∫mero de horas de formaci√≥n  realizadas  \\nhace dos a√±os. \\n \\n                                                            \\n3 Es comptabilitzen  les hores de formaci√≥ concedides  d‚Äôactivitats  volunt√†ries  pertanyents  al Pla de \\nFormaci√≥;  les hores certificades  dels cursos d‚Äôautoformaci√≥  i de proves de certificaci√≥  de la Unitat de \\nFormaci√≥,  i les hores concedides  de les activitats externes,  aix√≠ com les de formaci√≥ fetes en el Centre de', 'score': np.float32(0.9164475)}, {'id': '10166', 'content': '- Descripci√≥  de les accions que s‚Äôhan de desenvolupar  (t√≠tol de l‚Äôactivitat,  quantitat  d‚Äôhores, \\ndocent, lloc d‚Äôimpartici√≥,  modalitat  de formaci√≥‚Ä¶).  \\n- Col‚àôlectius, perfil del personal al qual va adre√ßada  l‚Äôacci√≥ i nombre total de places per cada \\nacci√≥ formativa.  \\n- Calendari  d‚Äôexecuci√≥  previst per a cada una de les accions formatives.  \\n- Distribuci√≥  de la formaci√≥ per als campus d‚ÄôAlcoi, Gandia i Val√®ncia. \\n- Idioma d‚Äôimpartici√≥  de l‚Äôactivitat.', 'score': np.float32(0.9252427)}, {'id': '40720', 'content': 'el cr√©dito ECTS, que computa la dedicaci√≥n  del \\nalumno, supondr√°  una dedicaci√≥n  reconocida  \\nm√°xima del profesor de 12 horas. \\n De este CREP, 10 horas ser√°n de actividad \\ndocente presencial  (clases organizadas  en sus \\ndiferentes  modalidades).  Por otra parte, el CREP \\nconstar√° adem√°s de 1 hora reconocida  por la \\nactividad de seguimiento  docente. El resto de \\nreconocimiento  de \\nla labor docente, hasta un \\nm√°ximo de 1 hora, quedar√° especificado  y', 'score': np.float32(0.9270414)}]}\n",
      "\n",
      "Pregunta: ¬øQu√© normativa regula el reconocimiento de horas?\n",
      "Respuesta: {'query': '¬øQu√© normativa regula el reconocimiento de horas?', 'context_used': '3471', 'response': 'No hay informaci√≥n suficiente en el contexto proporcionado para determinar espec√≠ficamente qu√© normativa regula el reconocimiento de horas. El texto menciona varios reglamentos y normativas de √≥rganos universitarios pero no aborda directamente el tema del reconocimiento de horas.', 'contexts': [{'id': '3471', 'content': 'expresa y excepcionalmente lo contrario.  \\n \\nLos reglamentos del Claustro, del Consejo de Gobierno, de los Centros, de los Departamentos, \\nde los Institutos Universitarios de Investigac i√≥n y de las Estructuras Propias de Investigaci√≥n, \\nas√≠ como las normativas de creaci√≥n de otros √≥rganos colegiados regulan la constituci√≥n y \\ndesarrollo de las sesiones sin que con car√°cter general se determine de manera presencial o a \\ndistancia.', 'score': np.float32(1.0277586)}, {'id': '41138', 'content': 'L‚Äôarticle 7 del Reial decret 412/2014, de 6 de juny, pel qual s‚Äôestableix la normativa b√†sica dels procediments d‚Äôadmissi√≥ als ensenyaments universitaris oficials de grau, estableix la interven ci√≥ necess√†ria de les universitats p√∫bliques en els criteris de \\nvaloraci√≥, les regles que s‚Äôhagen d‚Äôaplicar per a establir l‚Äôordre de prelaci√≥ en \\nl‚Äôadjudicaci√≥ de places i, si s‚Äôescau, els procediments d‚Äôadmissi√≥.', 'score': np.float32(1.027792)}, {'id': '78693', 'content': \"forma expressa i excepcional.  \\n \\nEls reglaments del Claustre, del Consell de Govern, dels centres, dels departaments, dels \\ninstituts universitaris d'investigaci√≥ i de les estructures pr√≤pies d'investigaci√≥, aix√≠ com les \\nnormatives de creaci√≥ d'altres √≤rgans col¬∑legiats, regulen la constituci√≥ i el desenvolupament \\nde les sessions sense que, amb car√†cter general, es determinen de manera presencial o a \\ndist√†ncia.\", 'score': np.float32(1.0316381)}]}\n",
      "\n",
      "Pregunta: ¬øExiste un m√°ximo de horas no presenciales por cr√©dito?\n",
      "Respuesta: {'query': '¬øExiste un m√°ximo de horas no presenciales por cr√©dito?', 'context_used': '38394', 'response': 'No hay informaci√≥n suficiente en el contexto proporcionado para determinar si existe un m√°ximo de horas no presenciales por cr√©dito. El texto se refiere a jornadas laborales y obligaciones del personal con dedicaci√≥n completa, pero no menciona espec√≠ficamente horas no presenciales por cr√©dito.', 'contexts': [{'id': '38394', 'content': '12.1.5.  En tot cas,  entre  el final  d‚Äôuna jornada  i el comen√ßament  de la seg√ºent  hi ha \\nd‚Äôhaver,  com a m√≠nim,  dotze  hores.  \\n \\n12.1.6.  S√≥n obligacions  del personal  amb  jornada  que t√© assignat  el complement  \\nespec√≠fic  de dedicaci√≥  completa, les  seg√ºents:  \\n \\na. Respondre  al requeriment  per a fer una jornada  setmanal  superior  a la que  li \\ncorrespon  quan  les necessitats  urgents  del servei aix√≠ ho exigeixen.', 'score': np.float32(0.9938213)}, {'id': '18793', 'content': '12.1.5.  En todo  caso,  entre  el final  de una jornada  y el comienzo  de la siguiente  mediar√°n,  \\ncomo  m√≠nimo,  doce  horas.  \\n \\n12.1.6.  Son obligaciones  del personal  con jornada  que tenga  asignado  el complemento  \\nespec√≠fico  de dedicaci√≥n  completa, las  siguientes:  \\n \\na. Responder  al requerimiento  para  la realizaci√≥n  de una jornada  semanal  \\nsuperior  a la que le corresponde  cuando  las necesidades  urgentes  del servicio  as√≠ lo exijan.', 'score': np.float32(1.0086882)}, {'id': '39000', 'content': 'correcte de l‚Äôacci√≥ formativa,  sense \\nque no superen un m√†xim anual de \\ncinquanta  hores. \\n2. Impartides  en modalitat  en l√≠nia \\nas√≠ncrona:  s‚Äôhan de desenvolupar  \\nfora de la jornada laboral i no \\ncomputen  en el cr√®dit de les \\ncinquanta  hores esmentat.  \\n \\nc) Per a assistir a les accions formatives  \\nexternes que tenen relaci√≥ amb el lloc de \\ntreball, es disposa d‚Äôuna llic√®ncia de \\ncinquanta  hores de conformitat  amb el \\nque es disposa en l‚Äôapartat 8.1.a de la \\npresent normativa.', 'score': np.float32(1.0093118)}]}\n"
     ]
    }
   ],
   "source": [
    "# otro_script.py\n",
    "\n",
    "from poli_gpt import PoliGPT\n",
    "\n",
    "def main():\n",
    "    # Inicializar una vez\n",
    "    poligpt_client = PoliGPT()\n",
    "    \n",
    "    # Consultar m√∫ltiples veces\n",
    "    preguntas = [\n",
    "        \"¬øCu√°ntas horas de docencia presencial tiene un cr√©dito?\",\n",
    "        \"¬øQu√© normativa regula el reconocimiento de horas?\",\n",
    "        \"¬øExiste un m√°ximo de horas no presenciales por cr√©dito?\"\n",
    "    ]\n",
    "    \n",
    "    for pregunta in preguntas:\n",
    "        respuesta = poligpt_client.query_poligpt(pregunta)\n",
    "        print(f\"\\nPregunta: {pregunta}\")\n",
    "        print(f\"Respuesta: {respuesta}\")\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
